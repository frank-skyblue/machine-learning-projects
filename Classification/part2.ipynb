{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.io import mmread\n",
    "\n",
    "# read the data\n",
    "# frequency matrix. Format: 2-D Array[i][j] -> \"freq of word i in article j\". Shape: (9635, 2225). 1-based indexing.\n",
    "freqMatrix = (mmread('./dataset/bbc.mtx'))\n",
    "freqMatrix = freqMatrix.todense()\n",
    "freqMatrixdf = pd.DataFrame(freqMatrix, range(1, freqMatrix.shape[0]+1), range(1, freqMatrix.shape[1]+1))\n",
    "\n",
    "# article # to label. Format: Array[i] -> [cluster label of article i]. Shape: (2225, 1). 0-based indexing.\n",
    "documentLabeldf = pd.read_csv('./dataset/bbc.classes', skiprows=4, sep=' ', header=None)\n",
    "documentLabeldf.columns = ['article', 'label']\n",
    "documentLabeldf = documentLabeldf.drop('article', axis=1)\n",
    "\n",
    "# word # to word. Format: Array[i] -> [actual word at word i]. Shape: (9635, 1). 0-based indexing.\n",
    "wordDictdf = pd.read_csv('./dataset/bbc.terms', header=None)\n",
    "wordDictdf.columns = ['WORD']\n",
    "\n",
    "# article # to article. Format: Array[i] -> [actual article at article i]. Shape: (2225, 1). 0-based indexing.\n",
    "articleDictdf = pd.read_csv('./dataset/bbc.docs', header=None)\n",
    "articleDictdf.columns = ['ARTICLE']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating training and testing datasets (Binary values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (1780, 9635)\n",
      "y_train.shape:  (1780, 1)\n",
      "X_test.shape:  (445, 9635)\n",
      "y_test.shape:  (445, 1)\n"
     ]
    }
   ],
   "source": [
    "# type: numpy.ndarray. Shape: (2225, 9635)\n",
    "# tranposed for better numpy indexing. mapped to binary values\n",
    "toZeroOne = np.vectorize(lambda x: 1 if x > 0 else 0)\n",
    "X_data = toZeroOne(freqMatrixdf.values.T)\n",
    "# type: numpy.ndarray. Shape: (2225, 1)\n",
    "y_data = documentLabeldf.values\n",
    "\n",
    "# type: numpy.ndarray. Shape: (9635, 1)\n",
    "wordDict = wordDictdf.values\n",
    "# type: numpy.ndarray. Shape: (2225, 1)\n",
    "articleDict = articleDictdf.values\n",
    "\n",
    "# split the data into train and test\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(X_data, y_data, test_size=0.2, random_state=40)\n",
    "\n",
    "print(\"X_train.shape: \", X_train.shape)\n",
    "print(\"y_train.shape: \", y_train.shape)\n",
    "print(\"X_test.shape: \", X_test.shape)\n",
    "print(\"y_test.shape: \", y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_params_NB(X, y):\n",
    "    \"\"\" Compute parameters for Naive Bayes classifier.\n",
    "    Args:\n",
    "    - X (ndarray (Shape: (N, D))): A NxD matrix corresponding to the inputs.\n",
    "    - y (ndarray (Shape: (N, 1))): A N-column vector corresponding to the outputs given the inputs.\n",
    "    \n",
    "    Output:\n",
    "    - A (ndarray (Shape: (D, K))): A NxD matrix corresponding to the ratio of the number of 1's in the i'th feature to its corresponding class j.\n",
    "    - b (ndarray (Shape: (K, 1))): A 1-column vector corresponding to the ratio of the number of samples in class j to the total number of samples.\n",
    "    \"\"\"\n",
    "\n",
    "    assert X.shape[0] == y.shape[0]\n",
    "    N = X.shape[0]\n",
    "    D = X.shape[1]\n",
    "    K = y.max() + 1\n",
    "\n",
    "    # calculating A matrix\n",
    "    A = np.zeros((D, K))\n",
    "    for label in range(K):\n",
    "        numElemsInLabel = np.count_nonzero(y == label)\n",
    "        whichIdxWithLabel = np.asarray(y == label).nonzero()[0]\n",
    "        for feature in range(D):\n",
    "            numOnesInFeatureAndLabel = np.count_nonzero(X[whichIdxWithLabel, feature])\n",
    "            A[feature, label] = (numOnesInFeatureAndLabel + 1) / (numElemsInLabel + 2) # Laplace smoothing\n",
    "\n",
    "    # calculating b vector\n",
    "    b = np.zeros((K, 1))\n",
    "    for label in range(K):\n",
    "        numElemsInLabel = np.count_nonzero(y == label)\n",
    "        b[label, 0] = numElemsInLabel / N\n",
    "    \n",
    "    assert (A >= 1).sum() == 0 # no feature has greater than or equal to 100% probability of being in a class\n",
    "    assert (A <= 0).sum() == 0 # no feature has less than or equal to 0% probability of being in a class\n",
    "    assert A.shape == (D, K)\n",
    "    assert b.shape == (K, 1)\n",
    "\n",
    "    return A, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "(A, b) = find_optimal_params_NB(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_NB(A, b, X):\n",
    "    \"\"\" Return predicted Y.\n",
    "    Args:\n",
    "    - X (ndarray (Shape: (N, D))): A NxD matrix corresponding to the inputs.\n",
    "    - A (ndarray (Shape: (D, K))): A NxD matrix corresponding to the ratio of the number of 1's in the i'th feature to its corresponding class j.\n",
    "    - b (ndarray (Shape: (K, 1))): A 1-column vector corresponding to the ratio of the number of samples in class j to the total number of samples.\n",
    "    \n",
    "    Output:\n",
    "    - y_pred (ndarray (Shape: (N, 1))): A N-column vector corresponding to the outputs given the inputs.\n",
    "    \"\"\"\n",
    "    N = X.shape[0]\n",
    "    K = A.shape[1]\n",
    "\n",
    "    y_pred = np.zeros((N, 1))\n",
    "\n",
    "    for index, featureVector in enumerate(X):\n",
    "        P_arr = np.zeros((K, 1))\n",
    "        a_j_arr = np.zeros((K, 1))\n",
    "        for label in range(K):\n",
    "            whichIdxWithOnes = np.asarray(featureVector == 1).nonzero()[0]\n",
    "            whichIdxWithZeroes = np.asarray(featureVector == 0).nonzero()[0]\n",
    "            sumOfLnProbsOnes = np.log(A[whichIdxWithOnes, label]).sum()\n",
    "            sumOfLnProbsZeroes = np.log(1-A[whichIdxWithZeroes, label]).sum()\n",
    "\n",
    "            a_j = sumOfLnProbsOnes + sumOfLnProbsZeroes + np.log(b[label, 0])\n",
    "            a_j_arr[label, 0] = a_j\n",
    "        \n",
    "        P_max = np.argmax(a_j_arr)\n",
    "        y_pred[index, 0] = P_max\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 98.65%\n",
      "Testing set accuracy: 95.96%\n"
     ]
    }
   ],
   "source": [
    "# Training set accuracy\n",
    "y_pred = get_pred_NB(A, b, X_train)\n",
    "total_training = y_train.shape[0]\n",
    "correct_training = np.count_nonzero(y_pred == y_train)\n",
    "print(str.format(\"Training set accuracy: {:.2f}%\", correct_training/total_training * 100))\n",
    "\n",
    "# Testing set accuracy\n",
    "y_pred = get_pred_NB(A, b, X_test)\n",
    "total_testing = y_test.shape[0]\n",
    "correct_testing = np.count_nonzero(y_pred == y_test)\n",
    "print(str.format(\"Testing set accuracy: {:.2f}%\", correct_testing/total_testing * 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting back to frequency values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (1780, 9635)\n",
      "y_train.shape:  (1780, 1)\n",
      "X_test.shape:  (445, 9635)\n",
      "y_test.shape:  (445, 1)\n"
     ]
    }
   ],
   "source": [
    "X_data = freqMatrixdf.values.T\n",
    "\n",
    "# split the data into train and test again\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(X_data, y_data, test_size=0.2, random_state=40)\n",
    "\n",
    "print(\"X_train.shape: \", X_train.shape)\n",
    "print(\"y_train.shape: \", y_train.shape)\n",
    "print(\"X_test.shape: \", X_test.shape)\n",
    "print(\"y_test.shape: \", y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Class Conditional Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Gaussian Class Conditional Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_Gaussian(x, mean, cov_mat_inv):\n",
    "    \"\"\" Calculate Gaussian distribution.\n",
    "    Args:\n",
    "    - x (ndarray (Shape: (D, 1))): A D-column vector corresponding to the input.\n",
    "    - mean (ndarray (Shape: (D, 1))): A D-column vector corresponding to the mean of the D features.\n",
    "    - cov_mat_inv (ndarray (Shape: (D, D))): A DxD matrix corresponding to the inverse covariance matrix of the D features.\n",
    "    \n",
    "    Output:\n",
    "    - Probability of data point x given mean and covariance.\n",
    "    \"\"\"\n",
    "    x_minus_mean = x - mean\n",
    "    exponent = -0.5 * (x_minus_mean.T @ cov_mat_inv @ x_minus_mean)\n",
    "\n",
    "    return exponent.item() # without constant term or exponent\n",
    "\n",
    "def find_optimal_params_GCC(X, y, bias_=0.0001):\n",
    "    \"\"\" Compute parameters for Gaussian Class Conditional classifier.\n",
    "    Args:\n",
    "    - X (ndarray (Shape: (N, D))): A NxD matrix corresponding to the inputs.\n",
    "    - y (ndarray (Shape: (N, 1))): A N-column vector corresponding to the outputs given the inputs.\n",
    "    \n",
    "    Output:\n",
    "    - means (ndarray (Shape: (D, K))): A D-column vector corresponding to the means of the D features for each class.\n",
    "    - cov_mats (ndarray (Shape: (D, D, K))): A DxD matrix corresponding to the covariance matrix of the D features for each class.\n",
    "    - priors (ndarray (Shape: (K, 1))): A 1-column vector corresponding to the prior probability of each class.\n",
    "    - features_included (ndarray (Shape: (D, K))): A D-column vector corresponding to the features included in the class.\n",
    "    \"\"\"\n",
    "    assert X.shape[0] == y.shape[0]\n",
    "    N = X.shape[0]\n",
    "    D = X.shape[1]\n",
    "    K = np.amax(y, axis=0).item() + 1\n",
    "\n",
    "    # Initializing the parameters\n",
    "    means = []\n",
    "    cov_mat_invs = []\n",
    "    priors = np.zeros((K, 1))\n",
    "    features_included = np.zeros((D, K))\n",
    "\n",
    "    for label in range(K):\n",
    "        X_with_label = X[y[:, 0] == label]\n",
    "        numElemsInLabel = X_with_label.shape[0]\n",
    "\n",
    "        # Reducing the number of features by removing features with variance of 0\n",
    "        variance_of_features = np.var(X_with_label, axis=0)\n",
    "        features_included[:,label] = np.where(variance_of_features > 0, 1, 0)\n",
    "\n",
    "        # Computing the mean and covariance matrix for each class\n",
    "        means.append(np.mean(X_with_label[:, features_included[:, label] == 1], axis=0).reshape(-1,1))\n",
    "        \n",
    "        # Adding a small bias to the covariance matrix to avoid singular matrix\n",
    "        cov_mat = np.cov(X_with_label[:, features_included[:, label] == 1], rowvar=False)\n",
    "        bias = bias_ * np.eye(cov_mat.shape[0])\n",
    "        cov_mat = cov_mat + bias\n",
    "        cov_mat_inv = np.linalg.inv(cov_mat)\n",
    "        cov_mat_invs.append(cov_mat_inv)\n",
    "\n",
    "        # Computing the prior probability for each class\n",
    "        priors[label, 0] = numElemsInLabel / N\n",
    "\n",
    "    return means, cov_mat_invs, priors, features_included"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the Gaussian Class Conditional Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_GCC(means, cov_mat_invs, priors, features_included, X):\n",
    "    \"\"\" Compute prediction for Gaussian Class Conditional classifier.\n",
    "    Args:\n",
    "    - means (ndarray (Shape: (D, K))): A D-column vector corresponding to the means of the D features for each class.\n",
    "    - cov_mat_invs (ndarray (Shape: (D, D, K))): A DxD matrix corresponding to the inverse covariance matrix of the D features for each class.\n",
    "    - priors (ndarray (Shape: (K, 1))): A 1-column vector corresponding to the prior probability of each class.\n",
    "    - features_included (ndarray (Shape: (D, K))): A D-column vector corresponding to the features included in the class.\n",
    "    - X (ndarray (Shape: (N, D))): A NxD matrix corresponding to the inputs.\n",
    "    \n",
    "    Output:\n",
    "    - y_pred (ndarray (Shape: (N, 1))): A N-column vector corresponding to the predicted outputs given the inputs.\n",
    "    \"\"\"\n",
    "    N = X.shape[0]\n",
    "    D = X.shape[1]\n",
    "    K = features_included.shape[1]\n",
    "    y_pred = np.zeros((N, 1))\n",
    "\n",
    "    for i in range(N):\n",
    "        max_prob = np.NINF\n",
    "        for j in range(K):\n",
    "            x_zero_features_removed = X[i, :].reshape(D, 1)[features_included[:, j] == 1, 0].reshape(-1, 1)\n",
    "            \n",
    "            prob = (calculate_Gaussian(x_zero_features_removed, means[j], cov_mat_invs[j]) * priors[j, 0]).item()\n",
    "            if prob > max_prob:\n",
    "                max_prob = prob\n",
    "                y_pred[i, 0] = j\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the optimal parameters\n",
    "(means, cov_mat_invs, priors, features_included) = find_optimal_params_GCC(X_train, y_train, bias_=0.00000001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Gaussian Class Conditional Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 100.00%\n",
      "Testing set accuracy: 69.44%\n"
     ]
    }
   ],
   "source": [
    "# Training set accuracy\n",
    "y_pred = get_pred_GCC(means, cov_mat_invs, priors, features_included, X_train)\n",
    "total_training = y_train.shape[0]\n",
    "correct_training = np.count_nonzero(y_pred == y_train)\n",
    "print(str.format(\"Training set accuracy: {:.2f}%\", correct_training/total_training * 100))\n",
    "\n",
    "# Testing set accuracy\n",
    "y_pred = get_pred_GCC(means, cov_mat_invs, priors, features_included, X_test)\n",
    "total_testing = y_test.shape[0]\n",
    "correct_testing = np.count_nonzero(y_pred == y_test)\n",
    "print(str.format(\"Testing set accuracy: {:.2f}%\", correct_testing/total_testing * 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results for the Gaussian Class Conditional Classifier is as follows:\n",
    "\n",
    "Training set accuracy: 100.00% <br>\n",
    "Testing set accuracy: 69.44%"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-NN Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the K-NN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNN_Classify(X_train, y_train, X, k):\n",
    "    \"\"\" Classifier using K-NN.\n",
    "    Args:\n",
    "    - X_train (ndarray (Shape: (N, D))): A NxD matrix corresponding to the training inputs.\n",
    "    - X (ndarray (Shape: (M, D))): A MxD matrix corresponding to the testing inputs.\n",
    "    - y_train (ndarray (Shape: (N, 1))): A N-column vector corresponding to the outputs given the inputs.\n",
    "    - k (int): Number of nearest neighbors to consider.\n",
    "    \n",
    "    Output:\n",
    "    - y_pred (ndarray (Shape: (M, 1))): A M-column vector corresponding to the outputs given the inputs.\n",
    "    \"\"\"\n",
    "    N = X_train.shape[0]\n",
    "    M = X.shape[0]\n",
    "\n",
    "    y_pred = np.zeros((M, 1))\n",
    "\n",
    "    for index, featureVector in enumerate(X):\n",
    "        dist_arr = np.zeros((N, 1))\n",
    "\n",
    "        for i in range(N):\n",
    "            dist = np.linalg.norm(featureVector - X_train[i])\n",
    "            dist_arr[i, 0] = dist\n",
    "\n",
    "        k_smallest_indexes = np.argpartition(dist_arr, k, axis=0)[:k].flatten()\n",
    "        labels_k_smallest = y_train[k_smallest_indexes].flatten()\n",
    "        label_counts = np.bincount(labels_k_smallest)\n",
    "\n",
    "        y_pred[index, 0] = np.argmax(label_counts)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the K-NN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 100.00% for k = 1\n",
      "Testing set accuracy: 79.33% for k = 1\n",
      "Training set accuracy: 86.85% for k = 3\n",
      "Testing set accuracy: 70.11% for k = 3\n",
      "Training set accuracy: 72.02% for k = 6\n",
      "Testing set accuracy: 64.72% for k = 6\n"
     ]
    }
   ],
   "source": [
    "# test the classifier\n",
    "testing_arr = [1, 3, 6]\n",
    "for k in testing_arr:\n",
    "    # training set accuracy\n",
    "    y_pred = kNN_Classify(X_train, y_train, X_train, k)\n",
    "    total_testing = y_train.shape[0]\n",
    "    correct_testing = np.count_nonzero(y_pred == y_train)\n",
    "    print(str.format(\"Training set accuracy: {:.2f}% for k = {}\", correct_testing/total_testing * 100, k))\n",
    "\n",
    "    # testing set accuracy\n",
    "    y_pred = kNN_Classify(X_train, y_train, X_test, k)\n",
    "    total_testing = y_test.shape[0]\n",
    "    correct_testing = np.count_nonzero(y_pred == y_test)\n",
    "    print(str.format(\"Testing set accuracy: {:.2f}% for k = {}\", correct_testing/total_testing * 100, k))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result for the K-NN classifier is as follows:\n",
    "\n",
    "Training set:\n",
    "<ul>\n",
    "    <li> Training set accuracy: 100.00% for k = 1\n",
    "    <li> Training set accuracy: 86.85% for k = 3\n",
    "    <li> Training set accuracy: 72.02% for k = 6\n",
    "</ul>\n",
    "\n",
    "Testing set:\n",
    "<ul>\n",
    "    <li> Testing set accuracy: 79.33% for k = 1\n",
    "    <li> Testing set accuracy: 70.11% for k = 3\n",
    "    <li> Testing set accuracy: 64.72% for k = 6\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
